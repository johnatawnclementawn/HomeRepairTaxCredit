---
title: "People Based ML - Housing Repair Tax Credit"
author: "Johnathan Clementi"
date: "11/5/2021"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	error = TRUE,
	message = FALSE,
	warning = FALSE,
	cache = TRUE
)

library(caret)
library(FNN)
library(ggcorrplot)
library(grid)
library(gridExtra)
library(htmltools)
library(kableExtra)
library(knitr)
library(lubridate)
library(plotROC)
library(pROC)
library(pscl)
library(sf)
library(spatstat)
library(spdep)
library(tidycensus)
library(tidyverse)
library(viridis)


options(scipen =  "sf")
options(scipen = 999)

# functions
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

palette5 <- c("#981FAC","#CB0F8B","#FF006A","#FE4C35","#FE9900")
palette4 <- c("#981FAC","#FF006A","#FE4C35","#FE9900")
palette2 <- c("#981FAC","#FF006A")
```

# 1. Introduction

The Department of Housing and Community Development (HCD) is interested in developing a more targeted and effective program for providing home repair tax credits. Historically, HCD has contacted homeowners and encouraged them to enroll in the program. However, only about 11% of eligible households who were contacted took the credit. A more effective program offers the prospect of neighborhood house value agglomeration in excess of $58,000, which corresponds to an \$8.40 increase in home values for every dollar spent by HCD. Below we compare the costs and benefits of the business-as-usual case to our honed model.   

### Data Processing and Exploration
The data dictionary for this dataset is contained below. In order to increase our predictive power, we have engineered new features.   

```{r}
dataDictionary <- read.csv("dataDictionary.csv") 

# Remove whitespace in records for Variable field
dataDictionary$Variable <- gsub(" ", "", dataDictionary$Variable, fixed = TRUE)
dataDictionary <- dataDictionary[-c(21),]

dataDictionary <- dataDictionary %>%
  mutate(Variables_NewNames = case_when(Variable == "age" ~ "indv.age",
                                        Variable == "job" ~ "indv.job",
                                        Variable == "marital" ~ "indv.marital",
                                        Variable == "education" ~ "indv.education",
                                        Variable == "taxbill_in_phl" ~ "indv.taxBillInPHL",
                                        Variable == "taxLien" ~ "house.taxLien",
                                        Variable == "mortgage" ~ "house.mortgage",
                                        Variable == "spent_on_repairs" ~ "house.spentOnRepairs",
                                        Variable == "contact" ~ "campaign.contact",
                                        Variable == "month" ~ "campaign.month",
                                        Variable == "day_of_week" ~ "campaign.dayOfWk",
                                        Variable == "campaign" ~ "campaign.numContacts",
                                        Variable == "pdays" ~ "campaign.numDaysPC",
                                        Variable == "previous" ~ "campaign.prevContact",
                                        Variable == "poutcome" ~ "campaign.prevOutcome",
                                        Variable == "unemploy_rate" ~ "env.unemploymentRate",
                                        Variable == "cons.price.idx" ~ "env.consPriceIdx",
                                        Variable == "cons.conf.idx" ~ "env.consConfIdx",
                                        Variable == "inflation_rate" ~ "env.inflationRate"
                             )

        ) %>%
  mutate(EngineeredVars = case_when(Variable == "age" ~ "eng.indv.age", 
                                    Variable == "job" ~ "eng.indv.job",
                                    Variable == "marital" ~ "eng.indv.marital",
                                    Variable == "education" ~ "eng.indv.edu",
                                    Variable == "campaign" ~ "eng.5orLessContacts",
                                    Variable == "poutcome" ~ "eng.prevOutcome",
                                    Variable == "unemploy_rate" ~ "eng.unemployRate"
                             )
        )

dataDictionary %>% dplyr::select(Variable, Variables_NewNames, EngineeredVars, Description) %>%
  kable() %>% kable_styling()

```

```{r include=FALSE}
housingSubsidy <- read.csv(paste0(root.dir,"Chapter6/housingSubsidy.csv"))

housingSubsidy <- housingSubsidy %>%
  rename(# Individual characteristics
          indv.age = age,
          indv.job = job,
          indv.marital = marital,
          indv.education = education,
          indv.taxBillInPHL = taxbill_in_phl,
          # House characteristics
          house.taxLien = taxLien,
          house.mortgage = mortgage,
          house.spentOnRepairs = spent_on_repairs,
          # Characteristics of the campaigns
          campaign.contact = contact,
          campaign.month = month,
          campaign.dayOfWk = day_of_week,
          campaign.numContacts = campaign,
          campaign.numDaysPC = pdays,
          campaign.prevContact = previous,
          campaign.prevOutcome = poutcome,
          # Economic environment factors
          env.unemploymentRate = unemploy_rate,
          env.consPriceIdx = cons.price.idx,
          env.consConfIdx = cons.conf.idx,
          env.inflationRate = inflation_rate,
        ) 
```

### Visualization

The figures below illustrate the relationship of existing features between an individual taking or not taking the tax credit. The first group of plots illustrate the average of that variable (e.g. number of contacts) for the group of people taking the tax credit (yes) and the group of people not taking the tax credit (no). Variables that illustrate significant differences across yes/no outcomes are useful for predicting whether an individual will take the credit.   
```{r message=FALSE, warning=FALSE}
housingSubsidy %>%
  dplyr::select(y, house.spentOnRepairs,env.consPriceIdx, env.consConfIdx, 
                env.unemploymentRate, env.inflationRate, campaign.numContacts, campaign.numDaysPC, indv.age) %>%
  gather(Variable, value, -y) %>%
    ggplot(aes(y, value, fill=y)) + 
      geom_bar(position = "dodge", stat = "summary", fun.y = "mean") + 
      facet_wrap(~Variable, scales = "free") +
      scale_fill_manual(values = palette2) +
      labs(x="Funds disbursed or not", y="Value", 
           title = "Feature associations with the likelihood of disembursement",
           subtitle = "(continous outcomes)") +
      theme(legend.position = "none")
```

The plots above can hide usable variation because they plot the mean. The plots below illustrate the frequency at which the variable occurs across its range for yes/no outcomes.   

```{r}
housingSubsidy %>%
    dplyr::select(y, house.spentOnRepairs,env.consPriceIdx, env.consConfIdx, 
                  env.unemploymentRate, env.inflationRate, campaign.numContacts, campaign.numDaysPC, indv.age) %>%
    gather(Variable, value, -y) %>%
    ggplot() +
    geom_density(aes(value, color=y), fill = "transparent") +
    facet_wrap(~Variable, scales = "free") +
    scale_fill_manual(values = palette2) +
    labs(title = "Feature distributions took credit vs. no credit",
         subtitle = "(continous features)")
```

These plots illustrate the proportion of yes/no across categorical variables. In this case, useful variables are those that exhibit variation of yes/no across the categories. For instance, we could predict that for whatever reason, people are more likely to take the subsidy in December and March.

```{r fig.width=10, fig.height= 10}
housingSubsidy %>%
  dplyr::select(y, indv.job, indv.marital, indv.education, campaign.contact, campaign.month, campaign.dayOfWk, house.mortgage, house.taxLien) %>%
  gather(Variable, value, -y) %>%
  count(Variable, value, y) %>%
  ggplot(aes(value, n, fill = y)) +   
    geom_bar(position = "fill", stat="identity") +
    facet_wrap(~Variable, scales="free") +
    scale_fill_manual(values = palette2) +
    labs(x="Disbursement", y="Percentage",
         title = "Feature associations with the likelihood of disembursement",
         subtitle = "Categorical features") +
    plotTheme() + theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Campaign month share
#table(housingSubsidy$campaign.month)
#round(table(housingSubsidy$campaign.month)/sum(table(housingSubsidy$campaign.month)),2)
```

```{r correlationMatrix, eval=FALSE, include=FALSE}
numericVars <- housingSubsidy %>% 
  select(where(is.numeric)) %>%
  select(-X) %>%
  na.omit()


ggcorrplot(
  round(cor(numericVars), 1), 
  p.mat = cor_pmat(numericVars),
  colors = c("#FA7800", "white", "#25CB10"),
  type="lower",
  insig = "blank") +  
    labs(title = "Correlation across numeric variables")


#trying to find variables that have a correlation value between 0.5 and -0.5
res <- as.data.frame(cor(numericVars)) %>%
  rownames_to_column()

#pivot longer and sort through list 
posCor <- res %>%
  select(!c("house.spentOnRepairs","y_numeric")) %>%
  pivot_longer(2:(ncol(res)-2)) %>%
  group_by(value) %>%
  arrange(desc(value)) %>%
  filter(value >= 0.1 & value <=0.6)

  

negCor <- res %>%
  select(!c("house.spentOnRepairs","y_numeric")) %>%
  pivot_longer(2:(ncol(res)-2)) %>%
  group_by(value) %>%
  arrange(desc(value)) %>%
  filter(value >= -0.6 & value <= -0.1)

corlist <- bind_rows(posCor,negCor)

corlist <- corlist %>%
  group_by(value) %>%
  arrange(desc(value))

#all odd numbers between 1 and 80
# Removes duplicates pairs that come from correlation matrix
keep <- c(1:nrow(corlist))
keep <- which(keep %% 2 == 1)

corlist <- corlist %>%
             slice(keep)

# includes all variables correlated with y_numeric
ynumCorlist <- corlist %>%
  filter(rowname == "y_numeric")

keep <- ynumCorlist$name

# categorical <- colnames(studentData %>%
#   select(where(is.factor)) %>%
#     st_drop_geometry())
# 
# 
# categorical <- c("Zip","District","price")
# keep <- append(keep, categorical)
```

# 2. Methods

### Engineering Features
By themselves, the features visualized above do not hold a lot of predictive power. Below, we engineer features to account for this and increase the predictive abilities of our models. Based on the observed distributions, we decided to engineer features for an individuals age, job status, marital status, educational status, time period (day & month), if the person had been contacted for this campaign less than 5 times, if the individual had previously taken the credit, and what the unemployment rate was at the time of contact. We found that most individuals taking subsidy were contacted 5 or less times. We found that most individuals taking subsidy were between 25 and 60. We found that people that took the subsidy previously are 64% likely to take the subsidy again. We found that people with HS degree or higher had at least a 10% chance of taking the subsidy. Finally, we found that When the unemployment rate is below -0.2, people are more likely to take the subsidy.   
```{r eval=FALSE, include=FALSE}
  
# # Identifying which variales to transform:
# yes <- housingSubsidy %>% filter(y_numeric == 1)
# 
# #Number of contacts for current campaign
# table(yes$campaign.numContacts)
# table(housingSubsidy$campaign.numContacts)
# # Most indv taking subsidy were contacted 5 or less times
# 
# # Age of indv
# table(yes$indv.age)
# table(housingSubsidy$indv.age)
# # Most indv taking subsidy were between 25 and 60
# 
# # Indv education
# temp <- housingSubsidy %>% filter(indv.education != "illiterate")
# table(temp$indv.education)
# table(yes$indv.education)/table(temp$indv.education)
# # People with HS degree or higher had at least a 10% chance of taking the subsidy
# 
# # Previous Outcome
# temp <- housingSubsidy %>% mutate(campaign.prevOutcome = case_when(campaign.prevOutcome == "failure" ~ 0,
#                                      campaign.prevOutcome == "nonexistent" ~ 0,
#                                      campaign.prevOutcome == "success" ~ 1
#                                      ))
# yes <- yes %>% mutate(campaign.prevOutcome = case_when(campaign.prevOutcome == "failure" ~ 0,
#                                      campaign.prevOutcome == "nonexistent" ~ 0,
#                                      campaign.prevOutcome == "success" ~ 1
#                                      ))
# table(yes$campaign.prevOutcome)
# table(temp$campaign.prevOutcome)
# table(yes$campaign.prevOutcome)/table(temp$campaign.prevOutcome)
# # People that took the subsidy previously are 64% likely to take the subsidy again
# 
# temp <- housingSubsidy %>% filter(env.unemploymentRate != -0.2)
# table(yes$env.unemploymentRate)
# table(temp$env.unemploymentRate)
# table(yes$env.unemploymentRate)/table(temp$env.unemploymentRate)
# # When the unemployment rate is below -0.2, people are more likely to take the subsidy
```

```{r}
# Engineer Features based on findings from code above
housingSubsidy <- housingSubsidy %>%
  mutate(eng.indv.job = indv.job) %>%# For engineered Features
  mutate(eng.indv.marital = case_when(indv.marital == "divorced" ~ "notMarried",
                                  indv.marital == "single" ~ "notMarried",
                                  indv.marital == "unknown" ~ "unknown",
                                  indv.marital == "married" ~ "married"
                                  )
         ) %>%
  # mutate(eng.indv.job = replace(eng.indv.job, eng.indv.job == "housemaid", "services"),
  #        eng.indv.job = replace(eng.indv.job, eng.indv.job == "self-employed", "entrepreneur"),
  #        eng.indv.job = replace(eng.indv.job, eng.indv.job == "retired", "notWorking"),
  #        eng.indv.job = replace(eng.indv.job, eng.indv.job == "student", "notWorking"),
  #        eng.indv.job = replace(eng.indv.job, eng.indv.job == "unemployed", "notWorking"),
  #        eng.indv.job = replace(eng.indv.job, eng.indv.job == "admin.", "admin")
  #       ) %>%
  mutate(eng.indv.edu = case_when(indv.education == "illiterate" ~ "BelowHS",
                                    indv.education == "basic.4y" ~ "BelowHS",
                                    indv.education == "basic.6y" ~ "BelowHS",
                                    indv.education == "basic.9y" ~ "BelowHS",
                                    indv.education == "high.school" ~ "HS_andAbove",
                                    indv.education == "professional.course" ~ "HS_andAbove",
                                    indv.education == "university.degree" ~ "HS_andAbove",
                                    indv.education == "unknown" ~ "unknown"
                                    )
         ) %>%
  mutate(eng.campaign.dayMonth = paste0(campaign.dayOfWk, "_", campaign.month),
         eng.5orLessContacts = case_when(campaign.numContacts < 6 ~ 1,
                                         campaign.numContacts > 5 ~ 0
                                        ),
         eng.indv.age = case_when(indv.age > 24 & indv.age < 61 ~ 1,
                             indv.age < 25 ~ 0,
                             indv.age > 60 ~ 0),
         eng.prevOutcome = case_when(campaign.prevOutcome == "failure" ~ 0,
                                     campaign.prevOutcome == "nonexistent" ~ 0,
                                     campaign.prevOutcome == "success" ~ 1
                                     ),
         eng.unemployRate = case_when(env.unemploymentRate >= -0.1 ~ 0,
                                      env.unemploymentRate < -0.1 ~ 1)
         )

```


### Training and Test Sets
We split the data into training and test sets for the purposes of building the models and then testing whether they can predict on unseen data.
```{r}
set.seed(3456)
trainIndex <- createDataPartition(housingSubsidy$y_numeric, p = .65,
                                  list = FALSE,
                                  times = 1)
creditTrain <- housingSubsidy[ trainIndex,] 
creditTest  <- housingSubsidy[-trainIndex,]
```

### BAU/'Kitchen Sink' Model Estimation
We estimate the business-as-usual prediction model. This is what we will compare our honed model to.
```{r}
kitchenSink_reg <- glm(y_numeric ~ .,
                  data=creditTrain %>% dplyr::select(-y, -starts_with("eng")),
                  family="binomial" (link="logit"))

# Predict disbursement for kitchen sink model
testProbs_Ksink <- data.frame(Outcome = as.factor(creditTest$y_numeric),
                        Probs = predict(kitchenSink_reg, creditTest, type= "response"))
#head(testProbs)

summary(kitchenSink_reg)

```

```{r}

```

### Honed Model Estimation
The engineered features are used to create a new prediction model.
```{r}
campaignCols <- colnames(housingSubsidy %>% select(starts_with("campaign")))
campaignCols <- campaignCols[campaignCols != "campaign.contact"]

honedReg <- glm(y_numeric ~ .,
                  data=creditTrain %>% dplyr::select(-y, starts_with("eng"), 
                                                     -starts_with("indv"), -starts_with("house"), 
                                                     -campaignCols
                                                     ),
                  family="binomial" (link="logit"))

# Predict disbursement for honed model
testProbs_honed <- data.frame(Outcome = as.factor(creditTest$y_numeric),
                        Probs = predict(honedReg, creditTest, type= "response"))
#head(testProbs_honed)

summary(honedReg)

```


# 3. Results Comparison

### McFadden R^2
The McFadden R^2 is a pseudo R^2 value. The higher the value, the better the model is at fitting its predictions to the data. These values indicate that our honed model is better fitted to the data.   
```{r}

paste("The honed model R^2 is:", round(pR2(kitchenSink_reg)[4],5))

paste("The honed model R^2 is:", round(pR2(honedReg)[4],5))
```


### Distributions of Predicted Probabilities
The figures below illustrate the distribution of predicted probabilities for an individual taking the tax credit or not (0 or 1). If the model was good at predicting all values,
the 'hump' for no tax credit would be focused on the 0.00 mark on the x-axis and the 'hump' for taking the tax credit would be located around the 1.00 mark on the x-axis.   
```{r, fig.height=8, fig.width=10}
grid.arrange(nrow = 2,
  ggplot(testProbs_Ksink, aes(x = Probs, fill = as.factor(Outcome))) + 
  geom_density() +
  facet_grid(Outcome ~ .) +
  scale_fill_manual(values = palette2) + xlim(0, 1) +
  labs(x = "Credit", y = "Density of probabilities",
       title = "Distribution of predicted probabilities by observed outcome\nKitchen Sink model") +
  plotTheme() + theme(strip.text.x = element_text(size = 18),
        legend.position = "none"),
  
  ggplot(testProbs_honed, aes(x = Probs, fill = as.factor(Outcome))) + 
    geom_density() +
    facet_grid(Outcome ~ .) +
    scale_fill_manual(values = palette2) + xlim(0, 1) +
    labs(x = "Credit", y = "Density of probabilities",
         title = "Distribution of predicted probabilities by observed outcome\nHoned Model") +
    plotTheme() + theme(strip.text.x = element_text(size = 18),
          legend.position = "none")
)
```

### Confusion Matrix
A confusion matrix and statistics allow us to measure a model's accuracy. An over-fit model would have zero occurrences in false negative and false positive quadrants (lower left and upper right). The goal of the honed model is to be able to add more predictive ability to move some false positives to true positives. 
```{r}
testProbs_Ksink <- testProbs_Ksink %>%
  mutate(predOutcome  = as.factor(ifelse(testProbs_Ksink$Probs > 0.5 , 1, 0)))

#head(testProbs_Ksink)

print('Kitchen Sink Model')
caret::confusionMatrix(testProbs_Ksink$predOutcome, testProbs_Ksink$Outcome, 
                       positive = "1")


testProbs_honed <- testProbs_honed %>%
  mutate(predOutcome  = as.factor(ifelse(testProbs_honed$Probs > 0.5 , 1, 0)))

#head(testProbs_honed)

print('Honed Model')
caret::confusionMatrix(testProbs_honed$predOutcome, testProbs_honed$Outcome, 
                       positive = "1")
```

### ROC Curves
"The Receiver Operating Characteristic Curve or ROC Curve is useful because it visualizes trade-offs for two important confusion metrics, while also providing a single goodness of fit indicator"(Steif, 2021). Because there are so few individuals taking the credit, it is hard to predict who will and who wont. The diagonal line from the bottom-left corner to the upper-right corner represents a coin-toss case. If our ROC line is above the coin-toss line, it indicates that we are at least better than a 50:50 chance of predicting the individual will take the tax credit. 

```{r message=FALSE, warning=FALSE}
grid.arrange(ncol = 2,
  ggplot(testProbs_Ksink, aes(d = as.numeric(testProbs_Ksink$Outcome), m = Probs)) +
    geom_roc(n.cuts = 50, labels = FALSE, colour = "#FE9900") +
    style_roc(theme = theme_grey) +
    geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
    labs(title = "ROC Curve - Kitchen Sink Model"),
  ggplot(testProbs_honed, aes(d = as.numeric(testProbs_honed$Outcome), m = Probs)) +
    geom_roc(n.cuts = 50, labels = FALSE, colour = "#FE9900") +
    style_roc(theme = theme_grey) +
    geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
    labs(title = "ROC Curve - Honed Model")
)

paste("The area under the curve is:", round(pROC::auc(testProbs_Ksink$Outcome, testProbs_Ksink$Probs),4),"for the Kitchen Sink model")
paste("The area under the curve is:", round(pROC::auc(testProbs_honed$Outcome, testProbs_honed$Probs),4),"for the Honed model")
```

### Cross Validation
```{r include=FALSE}
ctrl <- trainControl(method = "cv", number = 100, classProbs=TRUE, summaryFunction=twoClassSummary)

nonEngineered <- housingSubsidy %>% dplyr::select(-y_numeric, -starts_with("eng"))

cvFit_ks <- train(y ~ ., data=nonEngineered, 
                method="glm", family="binomial",
                metric="ROC", trControl = ctrl)

cvFit_hnd <- train(y ~ ., data=housingSubsidy %>% dplyr::select(y, starts_with("eng"), 
                                                     -starts_with("indv"), -starts_with("house"), 
                                                     -campaignCols), 
                method="glm", family="binomial",
                metric="ROC", trControl = ctrl)


cvFit_ks
cvFit_hnd

```

### Visualizing Cross Validation
Sensitivity is the proportion of individuals who took the tax credit to those predicted to take the credit. 
Specificity is the proportion of individuals who did not take the tax credit to those that were predicted to not take the credit. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
grid.arrange(nrow=2,
             dplyr::select(cvFit_ks$resample, -Resample) %>%
                gather(metric, value) %>%
                left_join(gather(cvFit_ks$results[2:4], metric, mean)) %>%
                ggplot(aes(value)) +
                  geom_histogram(bins=35, fill = "#FF006A") +
                  facet_wrap(~metric) +
                  geom_vline(aes(xintercept = mean), colour = "#981FAC", linetype = 3, size = 1.5) +
                  scale_x_continuous(limits = c(0, 1)) +
                  labs(x="Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics",
                       subtitle = paste('Kitchen sink model', " Across-fold mean reprented as dotted lines")) +
                  plotTheme(),
            dplyr::select(cvFit_hnd$resample, -Resample) %>%
                gather(metric, value) %>%
                left_join(gather(cvFit_hnd$results[2:4], metric, mean)) %>%
                ggplot(aes(value)) +
                  geom_histogram(bins=35, fill = "#FF006A") +
                  facet_wrap(~metric) +
                  geom_vline(aes(xintercept = mean), colour = "#981FAC", linetype = 3, size = 1.5) +
                  scale_x_continuous(limits = c(0, 1)) +
                  labs(x="Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics",
                       subtitle = paste('Honed model', " Across-fold mean reprented as dotted lines")) +
                  plotTheme()
            )

```




# 4. Analysis of Costs & Benefits

To compare the improvements of our engineered model to the business-as-usual (BAU) case, we present a cost benefit analysis below. We compare the costs incurred by the Government, with the benefits, which are generally collected by both the homeowner and their surrounding neighbors. If the accrual of home values outweighs the costs of spending tax dollars on the marketing and deployment of the subsidy, then HCD should adopt this method of prediction. 

Here are the potential costs: If we predict that a household will take the credit, then HCD is willing to allocate $2,850 per homeowner for marketing and support. These costs include staff and resources to facilitate mailers, phone calls, and information/counseling sessions at the HCD offices. This allocation is for every household to which the subsidy is marketed.
The subsidy itself is a $5,000 credit for improvements made to the house, This allocation is only for household who actually takes the credit.

It has been found that households previously engaging in the program saw an increase of $10,000 in their home's value.
Further, it has been found that the value of the homes surrounding the improved house saw a collective increase of $56,000 
(If there are 5 surrounding homes, each home saw an increase in value of $11,200.)

Tabulated below is the cost/benefit for one house of each prediction classification. Since tax dollars ultimately fund the program, and since we have no way of differentiating between neighborhoods in this study, the net benefits are those that the society at large accrues. 
```{r echo=FALSE, message=FALSE, warning=FALSE}
bind_cols(data.frame(Classification = c("True Positive","True Negative","False Positive","False Negative"),
                     Description = c("Predicted correctly homeowner would take the credit; allocated the marketing resources.",
                                     "Predicted correctly homeowner would not take the credit, no marketing resources were allocated, and no credit was allocated.",
                                     "Predicted incorrectly homeowner would take the credit; allocated marketing resources; no credit allocated.",
                                     "Predicted incorrectly homeowner would not take the credit; no marketing resources were allocated, but credit was allocated."),
                     Cost = c("-$2850-5000", "$0", "-$2850", "-$5000"),
                     Benefit = c("$10,000+56,000", "$0", "$0", "$10,000+56,000"),
                     Net_Benefit = c("$58,150", "$0", "-$2850", "$61,000")
                     )
          ) %>% 
  kable() %>% kable_styling()
```

### Calculated Costs/Benefits
```{r}
cost_benefit_table <-
   testProbs_honed %>%
      count(predOutcome, Outcome) %>%
      summarize(True_Positive = round(0.25 * sum(n[predOutcome==1 & Outcome==1]),0),
                True_Negative = sum(n[predOutcome==0 & Outcome==0]),
                False_Positive = sum(n[predOutcome==1 & Outcome==0]) + round(0.75 * sum(n[predOutcome==1 & Outcome==1]),0),
                False_Negative = sum(n[predOutcome==0 & Outcome==1])) %>%
       gather(Variable, Count) %>%
       mutate(Net_Benefit_USD = case_when(Variable == "True_Positive"  ~ 58150 * Count,
                                       Variable == "True_Negative"  ~ 0 * Count,
                                       Variable == "False_Positive" ~ (-2850) * Count,
                                       Variable == "False_Negative" ~ 61000 * Count
                                      )
              ) %>%
      bind_cols(data.frame(Description = c("Predicted correctly homeowner would take the credit; allocated the marketing resources.",
                                       "Predicted correctly homeowner would not take the credit, no marketing resources were allocated, and no credit was allocated.",
                                       "Predicted incorrectly homeowner would take the credit; allocated marketing resources; no credit allocated.",
                                       "Predicted incorrectly homeowner would not take the credit; no marketing resources were allocated, but credit was allocated.")
                          )
                )

cost_benefit_table %>% kable() %>% kable_styling()
```

```{r}
whichThreshold <- 
  iterateThresholds(
    data=testProbs_honed, observedClass = Outcome, predictedProbs = Probs) %>%
    dplyr::select(starts_with("Count"), Threshold) %>%
    gather(Variable, Count, -Threshold) %>%
    mutate(Revenue =
             case_when(Variable == "Count_TP"  ~ 58150 * Count,
                       Variable == "Count_TN"  ~ 0 * Count,
                       Variable == "Count_FP"  ~ (-2850) * Count,
                       Variable == "Count_FN"  ~ 61000 * Count
                       )
          )

whichThreshold %>%
  ggplot(.,aes(Threshold, Revenue, colour = Variable)) +
  geom_point() +
  scale_colour_manual(values = palette5[c(5, 1:3)]) +    
  labs(title = "Revenue by confusion matrix type and threshold",
       y = "Revenue") +
  plotTheme() +
  guides(colour=guide_legend(title = "Confusion Matrix")) 
```
```{r}
whichThreshold_revenue <- 
  whichThreshold %>% 
    mutate(Total_Count_of_Credits = ifelse(Variable == "Count_TP", (Count * .25),
                                 ifelse(Variable == "Count_FN", Count, 0))) %>% 
    group_by(Threshold) %>% 
    summarize(Total_Revenue = sum(Revenue),
              Total_Credits_Rate = sum(Total_Count_of_Credits) / sum(Count),
              Total_Count_of_Credits = sum(Total_Count_of_Credits)) 

whichThreshold_revenue %>%
  dplyr::select(Threshold, Total_Revenue, Total_Count_of_Credits) %>%
  gather(Variable, Value, -Threshold) %>%
  ggplot(aes(Value, Threshold, colour = Variable)) +
    geom_point() +
    geom_hline(yintercept = pull(arrange(whichThreshold_revenue, -Total_Revenue)[1,1])) +
    scale_colour_manual(values = palette2) +
    facet_wrap(~Variable, scale = "free") +
    plotTheme() +
    labs(title = "Threshold by revenue and number of taken credits",
         subtitle = "Horizontal line denotes optimal threshold by revenue")
```


```{r}
optimal_threshold = pull(arrange(whichThreshold_revenue, -Total_Revenue)[1,1])

whichThreshold_revenue %>% 
  filter(Threshold == .5 | Threshold == optimal_threshold) %>% 
  dplyr::select(Total_Revenue, Total_Count_of_Credits) %>% 
  cbind(data.frame(Model = c("OptimalThreshold", "50% Threshold")),.) %>% 
  kable() %>%
  kable_styling("striped", full_width = F)
```

# 5. Conclusion


# 6. Appendix
### Citations
1. [Public Policy Analytics, Steif K., 2021, accessed 2021-09-23](https://urbanspatial.github.io/PublicPolicyAnalytics/)
